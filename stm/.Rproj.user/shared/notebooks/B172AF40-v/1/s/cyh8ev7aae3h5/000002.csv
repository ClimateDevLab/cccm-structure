"0","```r
processed <- textProcessor(data$text, metadata = data, stem = T)
```"
"1","Building corpus... 
Converting to Lower Case... 
Removing punctuation... 
Removing stopwords... 
Removing numbers... 
Stemming... 
Creating Output... 
"
"0","```r
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
```"
"1","Removing 613021 of 845360 terms (613021 of 14035897 tokens) due to frequency 
Your corpus now has 151719 documents, 232339 terms and 13422876 tokens.
"
"0","```r
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
```"
